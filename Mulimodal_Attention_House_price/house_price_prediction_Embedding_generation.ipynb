{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65bc80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "set_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deb779b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data = pd.read_csv('all_after_preprocessingStopwords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0c78c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10251"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numerical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ca2353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer,BertModel,get_linear_schedule_with_warmup, RobertaTokenizer, RobertaModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "def Data_preprocessing(df):\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # Numerical Feature\n",
    "    numerical_features = [\"bedroom\",\"bedroomAboveGrade\",\"bedroomBelowGrade\",\"bathroom\", \"bathroomTotal\",\"bathroomPartial\", \n",
    "                        \"totalParkingSpaces\", \"storeys\", \"maintenanceFees\",  'landSize']\n",
    "    \n",
    "    X_num = df[numerical_features]\n",
    "    X_num = scaler.fit_transform(X_num)\n",
    "    X_num = pd.DataFrame(X_num)\n",
    "    df[\"longitude\"] = df[\"longitude\"] *0.01\n",
    "    df[\"latitude\"] = df[\"latitude\"] *0.01\n",
    "    df[numerical_features] = X_num\n",
    "          \n",
    "    # Boolean Feature\n",
    "    boolean_features=['parkingAttachedGarage',\n",
    "       'parkingUnderground', 'parkingInsideEntry', 'parkingSurfaced',\n",
    "       'parkingOversize', 'parkingGravel', 'parkingGarage', 'parkingShared',\n",
    "       'parkingDetachedGarage', 'parkingCarport', 'parkingInterlocked',\n",
    "       'parkingVisitorParking','amenityClubhouse', 'amenityCarWash', 'amenityMusicRoom',\n",
    "       'amenityStorageLocker', 'amenitySauna', 'amenityPartyRoom',\n",
    "       'amenityRecreationCentre', 'amenityGuestSuite', 'amenityFurnished',\n",
    "       'amenityLaundryFacility', 'amenityExerciseCentre',\n",
    "       'amenityLaundryInSuite', 'amenitySecurity', 'amenityWhirlpool',\n",
    "       'efinishWood', 'efinishBrick', 'efinishHardboard', 'efinishWoodsiding',\n",
    "       'efinishLog', 'efinishMetal', 'efinishSteel', 'efinishStone',\n",
    "       'efinishWoodshingles', 'efinishStucco', 'efinishSiding',\n",
    "       'efinishConcrete', 'efinishShingles', 'efinishAluminumsiding',\n",
    "       'efinishCedarshingles', 'efinishVinyl', 'efinishVinylsiding',\n",
    "       'featurePetNotAllowed', 'AirportNearby',\n",
    "       'GolfNearby', 'MarinaNearby', 'ShoppingNearby', 'WaterNearby',\n",
    "       'WorshipPlaceNearby', 'RecreationNearby', 'PlaygroundNearby',\n",
    "       'PublicTransitNearby', 'ParkNearby', 'SchoolsNearby', 'HospitalNearby',\n",
    "       'HighwayNearby', 'SkiAreaNearby']\n",
    "    \n",
    "    # Category Feature\n",
    "    cate_features = ['city', 'typeBuilding', 'title', 'styleAttach', \n",
    "                   'cooling',  'basementType', 'basementFinish',\n",
    "                   'heatingType1', 'heatingType2', 'heatingEnergy1', 'heatingEnergy2', \n",
    "                   'featureLotSlope', 'featureDriveway', 'featureLotPositionType',\n",
    "       'featureOutdoorAreaType', 'featureOutdoorLandscape',\n",
    "       'featureAdditionalFacility']\n",
    "    \n",
    "    X_category=df[cate_features]\n",
    "    for col in cate_features:\n",
    "        X_category[col] = X_category[col].astype('category')\n",
    "        X_category[col] = X_category[col].cat.codes\n",
    "    df[cate_features] = X_category\n",
    "    \n",
    "    # Label Price\n",
    "    price_range = []\n",
    "    \n",
    "    for price in df[\"price\"]:\n",
    "        if price < 5e5:\n",
    "            price_range.append(0)\n",
    "        elif 5e5<=price < 15e5:\n",
    "            price_range.append(1)\n",
    "        elif 15e5<=price < 25e5:\n",
    "            price_range.append(2)\n",
    "        elif 25e5<=price < 35e5:\n",
    "            price_range.append(3)\n",
    "        elif 35e5<=price < 80e5:\n",
    "            price_range.append(4)\n",
    "        else:\n",
    "            price_range.append(5)\n",
    "            \n",
    "#     df = df.reset_index(drop=True)\n",
    "    df['price_range'] = price_range\n",
    "    df = df.dropna()\n",
    "    return df, boolean_features, cate_features, numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e62aec47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-f5456da299cf>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_category[col] = X_category[col].astype('category')\n",
      "<ipython-input-5-f5456da299cf>:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_category[col] = X_category[col].cat.codes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "preprocessed_data, boolean_features, cate_features, numerical_features = Data_preprocessing(numerical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bac521bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of categorical feature is : 17, boolean feature is : 58, numerical feature is : 10\n"
     ]
    }
   ],
   "source": [
    "cate_num = len(cate_features)\n",
    "bool_num =  len(boolean_features)\n",
    "num_num = len(numerical_features)\n",
    "print('The number of categorical feature is : {}, boolean feature is : {}, numerical feature is : {}'.format(cate_num, bool_num, num_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "285d2f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generate_dataset(Dataset):\n",
    "    def __init__(self, data_df, tokenizer, boolean_features,cate_features, numerical_features):\n",
    "        self.MAX_SEQ_LEN = 128\n",
    "        self.data = data_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.boolean = boolean_features\n",
    "        self.cate = cate_features\n",
    "        self.numerical = numerical_features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        boolean_feature = torch.tensor(list(self.data.iloc[idx][self.boolean]))\n",
    "        cate_feature = torch.tensor(list(self.data.iloc[idx][self.cate]))\n",
    "        numerical_feature = torch.tensor(list(self.data.iloc[idx][self.numerical]))\n",
    "        description = self.data.iloc[idx]['description']\n",
    "        word_encode = torch.tensor(self.tokenizer.encode(text= description,max_length=self.MAX_SEQ_LEN,padding='max_length', truncation=True))\n",
    "        label = torch.tensor(float(self.data.iloc[idx]['price']))\n",
    "        label_range =  torch.tensor(int(self.data.iloc[idx]['price_range']))\n",
    "        \n",
    "        return {'description': word_encode, 'numerical_feature':numerical_feature, 'cate_feature':cate_feature, 'boolean_feature':boolean_feature, 'label':label, 'label_range':label_range}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "042f0a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset = Generate_dataset(preprocessed_data, tokenizer, boolean_features,cate_features, numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d957ba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataloader = DataLoader(all_dataset, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e30ed221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "BERT_org = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38b5f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class BERT_Predictor(torch.nn.Module):\n",
    "    def __init__(self, pretrained_model, tokenizer, predictor_size = 1, multi_mode = None):\n",
    "        super(BERT_Predictor, self).__init__()\n",
    "        \n",
    "        self.bert = pretrained_model\n",
    "        self.PAD_INDEX = tokenizer.pad_token_id\n",
    "    \n",
    "        self.final_embed = 36\n",
    "        \n",
    "        if multi_mode is not None:\n",
    "            self.cat_num = multi_mode['cate_num']\n",
    "            self.bool_num = multi_mode['bool_num']\n",
    "            self.num_num = multi_mode['num_num']\n",
    "        \n",
    "        self.cat_encoder = torch.nn.Linear(self.cat_num,self.final_embed)\n",
    "        self.bool_encoder = torch.nn.Linear(self.bool_num,self.final_embed)\n",
    "        self.num_encoder = torch.nn.Linear(self.num_num,self.final_embed)\n",
    "        self.des_encoder =  torch.nn.Linear(768,self.final_embed)\n",
    "        \n",
    "        self.multihead_attn = torch.nn.MultiheadAttention(self.final_embed, 12, dropout = 0.2, batch_first = True)\n",
    "        self.layer_norm = torch.nn.LayerNorm(self.final_embed)\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        \n",
    "        self.predictor = torch.nn.ModuleList()\n",
    "        for _ in range(predictor_size):\n",
    "            self.predictor.append(torch.nn.Linear(self.final_embed,self.final_embed))\n",
    "            self.predictor.append(torch.nn.ReLU())\n",
    "            self.predictor.append(torch.nn.Dropout(0.2))\n",
    "            \n",
    "        self.prediction = torch.nn.Linear(self.final_embed, 6)\n",
    "\n",
    "\n",
    "    def forward(self,input_ids, cat_feature = None, numerical_feature = None, bool_feature = None, extract_feature = False):\n",
    "        attention_mask = (input_ids != self.PAD_INDEX).type(torch.uint8)\n",
    "\n",
    "        outputs = self.bert(input_ids,attention_mask=attention_mask)\n",
    "        final_output = outputs[0]\n",
    "        \n",
    "        cat_feature = cat_feature.float()\n",
    "        numerical_feature = numerical_feature.float()\n",
    "        bool_feature = bool_feature.float()\n",
    "        \n",
    "        \n",
    "        cat_feature_final = self.cat_encoder(cat_feature).unsqueeze(1)\n",
    "        numerical_feature_final = self.num_encoder(numerical_feature).unsqueeze(1)\n",
    "        bool_feature_final = self.bool_encoder(bool_feature).unsqueeze(1)\n",
    "        des_output = self.des_encoder(final_output)\n",
    "        \n",
    "        numerical = torch.cat((cat_feature_final, numerical_feature_final, bool_feature_final, des_output), 1)\n",
    "        \n",
    "        attn_output, _ = self.multihead_attn(numerical, numerical, numerical)\n",
    "        attn_output  = self.dropout(attn_output)\n",
    "        attn_output = attn_output\n",
    "        attn_output = self.layer_norm(attn_output + numerical)\n",
    "        \n",
    "        if extract_feature:\n",
    "            return attn_output\n",
    "        \n",
    "        pooled_output = torch.mean(attn_output, dim = 1)\n",
    "        for layer in self.predictor:\n",
    "            pooled_output = layer(pooled_output)\n",
    "\n",
    "        prediction = self.prediction(pooled_output)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bb9f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_mode = {'cate_num': cate_num, 'bool_num':bool_num, 'num_num':num_num}\n",
    "Bert_regressor = BERT_Predictor(BERT_org, tokenizer,multi_mode = multi_mode).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6be15721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bert_regressor.load_state_dict(torch.load('Bert_self_attention.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fec318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def data_extraction(model, test_iter):\n",
    "    data_embeddings = []\n",
    "    data_labels = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data in tqdm(test_iter):\n",
    "            source = data['description'].to(device)\n",
    "            target_range = data['label_range'].to(device).unsqueeze(-1)\n",
    "            cat_feature = data['cate_feature'].to(device)\n",
    "            numerical_feature = data[ 'numerical_feature'].to(device)\n",
    "            bool_feature = data['boolean_feature'].to(device)\n",
    "            embeddings = model(input_ids=source,cat_feature = cat_feature, numerical_feature = numerical_feature, bool_feature = bool_feature,extract_feature = True)\n",
    "            data_embeddings.extend(embeddings.tolist())\n",
    "            data_labels.extend(target_range.tolist())\n",
    "    \n",
    "    data_labels = list(np.array(data_labels).reshape(-1))\n",
    "    return data_embeddings, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "343bd7cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/641 [00:00<?, ?it/s]<ipython-input-8-01fb23d2cb29>:17: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  boolean_feature = torch.tensor(list(self.data.iloc[idx][self.boolean]))\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 641/641 [01:42<00:00,  6.23it/s]\n"
     ]
    }
   ],
   "source": [
    "data_embeddings, data_labels = data_extraction(Bert_regressor, all_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8977316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10243, 131, 36)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aeea5563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-e7de0c20b035>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data_embeddings = torch.tensor(data_embeddings)\n"
     ]
    }
   ],
   "source": [
    "data_embeddings = torch.tensor(data_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "716c3cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = torch.tensor(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef181135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10243])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6302e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data_embeddings, 'sample_embeddding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5bcd742",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data_labels, 'data_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d0d817",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
