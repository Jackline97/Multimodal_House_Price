{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.firefox_binary import FirefoxBinary\n",
    "from bs4 import BeautifulSoup\n",
    "import io\n",
    "from fake_useragent import UserAgent\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The project folder for the web crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder=\"C:/Users/hanson/OneDrive/Grad/Grad Project/data_realtorCA/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variable \"realtor_url\" leads to the first web page in the search result\n",
    "## The search result should contain 50 pages or fewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realtor_url = 'https://www.realtor.ca/map#ZoomLevel=10&Center=43.298145%2C-79.767728&LatitudeMax=43.69513&LongitudeMax=-78.68008&LatitudeMin=42.89855&LongitudeMin=-80.85537&view=list&Sort=1-A&GeoIds=g30_dpxnh9by&GeoName=Hamilton%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMin=1200001&Currency=CAD'\n",
    "#realtor_url = 'https://www.realtor.ca/map#ZoomLevel=10&Center=43.298145%2C-79.767728&LatitudeMax=43.69513&LongitudeMax=-78.68008&LatitudeMin=42.89855&LongitudeMin=-80.85537&view=list&Sort=1-A&GeoIds=g30_dpxnh9by&GeoName=Hamilton%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMin=690001&PriceMax=1200000&Currency=CAD'\n",
    "#realtor_url = 'https://www.realtor.ca/map#ZoomLevel=10&Center=43.298145%2C-79.767728&LatitudeMax=43.69513&LongitudeMax=-78.68008&LatitudeMin=42.89855&LongitudeMin=-80.85537&view=list&Sort=1-A&GeoIds=g30_dpxnh9by&GeoName=Hamilton%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMax=690000&Currency=CAD'\n",
    "#realtor_url = 'https://www.realtor.ca/map#ZoomLevel=11&Center=43.725101%2C-79.759570&LatitudeMax=43.92252&LongitudeMax=-79.21575&LatitudeMin=43.52703&LongitudeMin=-80.30339&view=list&Sort=1-A&GeoIds=g30_dpz29nnj&GeoName=Brampton%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMin=950001&Currency=CAD'\n",
    "#realtor_url = 'https://www.realtor.ca/map#ZoomLevel=11&Center=43.725101%2C-79.759570&LatitudeMax=43.92252&LongitudeMax=-79.21575&LatitudeMin=43.52703&LongitudeMin=-80.30339&view=list&Sort=1-A&GeoIds=g30_dpz29nnj&GeoName=Brampton%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMax=950000&Currency=CAD'\n",
    "#realtor_url = 'https://www.realtor.ca/map#ZoomLevel=11&Center=43.613223%2C-79.641886&LatitudeMax=43.81101&LongitudeMax=-79.09806&LatitudeMin=43.41479&LongitudeMin=-80.18571&view=list&Sort=1-A&GeoIds=g30_dpxrgruz&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMin=900001&Currency=CAD'\n",
    "#realtor_url = 'https://www.realtor.ca/map#ZoomLevel=11&Center=43.606263%2C-79.666605&LatitudeMax=43.80407&LongitudeMax=-79.12278&LatitudeMin=43.40780&LongitudeMin=-80.21043&view=list&Sort=1-A&GeoIds=g30_dpxrgruz&GeoName=Mississauga%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMax=900000&Currency=CAD'\n",
    "#realtor_url = 'https://www.realtor.ca/map#ZoomLevel=11&Center=43.708087%2C-79.376385&LatitudeMax=43.90556&LongitudeMax=-78.83256&LatitudeMin=43.50996&LongitudeMin=-79.92021&view=list&Sort=1-A&GeoIds=g30_dpz89rm7&GeoName=Toronto%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMin=3500001&Currency=CAD'\n",
    "#realtor_url = 'https://www.realtor.ca/map#ZoomLevel=11&Center=43.708087%2C-79.376385&LatitudeMax=43.90556&LongitudeMax=-78.83256&LatitudeMin=43.50996&LongitudeMin=-79.92021&view=list&Sort=1-A&GeoIds=g30_dpz89rm7&GeoName=Toronto%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMin=2000001&PriceMax=3500000&Currency=CAD'\n",
    "#realtor_url = 'https://www.realtor.ca/map#ZoomLevel=11&Center=43.708087%2C-79.376385&LatitudeMax=43.90556&LongitudeMax=-78.83256&LatitudeMin=43.50996&LongitudeMin=-79.92021&view=list&Sort=1-A&GeoIds=g30_dpz89rm7&GeoName=Toronto%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMin=1500001&PriceMax=2000000&Currency=CAD'\n",
    "#realtor_url = 'https://www.realtor.ca/map#ZoomLevel=11&Center=43.708087%2C-79.376385&LatitudeMax=43.90556&LongitudeMax=-78.83256&LatitudeMin=43.50996&LongitudeMin=-79.92021&view=list&Sort=1-A&GeoIds=g30_dpz89rm7&GeoName=Toronto%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMin=1200001&PriceMax=1500000&Currency=CAD'\n",
    "#realtor_url = 'https://www.realtor.ca/map#ZoomLevel=11&Center=43.708087%2C-79.376385&LatitudeMax=43.90556&LongitudeMax=-78.83256&LatitudeMin=43.50996&LongitudeMin=-79.92021&view=list&Sort=1-A&GeoIds=g30_dpz89rm7&GeoName=Toronto%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMin=999001&PriceMax=1200000&Currency=CAD'\n",
    "#realtor_url = 'https://www.realtor.ca/map#ZoomLevel=11&Center=43.708087%2C-79.376385&LatitudeMax=43.90556&LongitudeMax=-78.83256&LatitudeMin=43.50996&LongitudeMin=-79.92021&view=list&Sort=1-A&GeoIds=g30_dpz89rm7&GeoName=Toronto%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMin=890001&PriceMax=999000&Currency=CAD'\n",
    "#realtor_url= 'https://www.realtor.ca/map#ZoomLevel=11&Center=43.708087%2C-79.376385&LatitudeMax=43.90556&LongitudeMax=-78.83256&LatitudeMin=43.50996&LongitudeMin=-79.92021&view=list&Sort=1-A&GeoIds=g30_dpz89rm7&GeoName=Toronto%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMin=790001&PriceMax=890000&Currency=CAD'\n",
    "#realtor_url = 'https://www.realtor.ca/map#ZoomLevel=11&Center=43.708087%2C-79.376385&LatitudeMax=43.90556&LongitudeMax=-78.83256&LatitudeMin=43.50996&LongitudeMin=-79.92021&view=list&Sort=1-A&GeoIds=g30_dpz89rm7&GeoName=Toronto%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMin=690001&PriceMax=790000&Currency=CAD'\n",
    "#realtor_url = 'https://www.realtor.ca/map#ZoomLevel=11&Center=43.708087%2C-79.376385&LatitudeMax=43.90556&LongitudeMax=-78.83256&LatitudeMin=43.50996&LongitudeMin=-79.92021&view=list&Sort=1-A&GeoIds=g30_dpz89rm7&GeoName=Toronto%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMin=600001&PriceMax=690000&Currency=CAD'\n",
    "#realtor_url = 'https://www.realtor.ca/map#ZoomLevel=11&Center=43.708087%2C-79.376385&LatitudeMax=43.90556&LongitudeMax=-78.83256&LatitudeMin=43.50996&LongitudeMin=-79.92021&view=list&Sort=1-A&GeoIds=g30_dpz89rm7&GeoName=Toronto%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMin=540001&PriceMax=600000&Currency=CAD'\n",
    "#realtor_url = 'https://www.realtor.ca/map#ZoomLevel=11&Center=43.708087%2C-79.376385&LatitudeMax=43.90482&LongitudeMax=-78.83256&LatitudeMin=43.51071&LongitudeMin=-79.92021&view=list&Sort=1-A&GeoIds=g30_dpz89rm7&GeoName=Toronto%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMax=540000&Currency=CAD'\n",
    "#realtor_url = \"https://www.realtor.ca/map#ZoomLevel=11&Center=43.708087%2C-79.376385&LatitudeMax=43.90556&LongitudeMax=-78.83256&LatitudeMin=43.50996&LongitudeMin=-79.92021&Sort=1-A&GeoIds=g30_dpz89rm7&GeoName=Toronto%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMax=540000&Currency=CAD\"\n",
    "#realtor_url = 'https://www.realtor.ca/on/ottawa/real-estate-for-sale'\n",
    "#realtor_url = 'https://www.realtor.ca/map#view=list&Sort=1-A&GeoIds=g30_f241etq5&GeoName=Ottawa%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMax=600000&Currency=CAD'\n",
    "#realtor_url = 'https://www.realtor.ca/map#view=list&Sort=1-A&GeoIds=g30_f241etq5&GeoName=Ottawa%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMin=600001&PriceMax=1800000&Currency=CAD'\n",
    "#realtor_url = 'https://www.realtor.ca/map#view=list&Sort=1-A&GeoIds=g30_f241etq5&GeoName=Ottawa%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMin=1800001&Currency=CAD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The element in HTML to click the next page button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_next_button = \"/html/body/form/div[5]/div[2]/span/div/div[4]/div[3]/span/span/div/a[3]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visit and save the search result web pages to \"project_folder+\"saved_pages\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first page needs the user to pass human verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# launching forefox webdriver\n",
    "## Specify where the webdriver file is\n",
    "driver = webdriver.Firefox(executable_path='C:/Users/hanson/OneDrive/Grad/Grad Project/bin/geckodriver')\n",
    "\n",
    "# saving all the search result pages\n",
    "def scrapping_function(current_url, click_next_button):\n",
    "    #Visit the first page in search result, the first page always triggers human verification\n",
    "    driver.get(current_url)\n",
    "    time.sleep(120) #Give the user 2 minutes to do the \"I'm not robot\" verification\n",
    "    i = 1\n",
    "    next_page_true = True\n",
    "    while next_page_true:\n",
    "        time.sleep(2)\n",
    "        page = driver.page_source\n",
    "        file_ = io.open(project_folder+'saved_pages/page_{}.html'.format(i), 'w', encoding=\"utf-8\")\n",
    "        file_.write(page)\n",
    "        file_.close()\n",
    "        time.sleep(1.85)\n",
    "        page_url = driver.current_url\n",
    "        time.sleep(2)\n",
    "        # Find and click the next button\n",
    "        elem = driver.find_element_by_xpath(click_next_button)\n",
    "        elem.click()\n",
    "        time.sleep(2)\n",
    "        time.sleep(0.25)\n",
    "        page_url_next = driver.current_url\n",
    "\n",
    "        # If the next page button is clicked but the web page does not change\n",
    "        # The end of the search result is reached, or the page #50 is reached \n",
    "        if page_url == page_url_next:\n",
    "            next_page_true = False\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "# calling the scrapping function on the search result \"realtor_url\"\n",
    "scrapping_function(realtor_url, click_next_button)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract URLs of the house listing pages from the saved search result pages\n",
    "## Save the data frame that contains URLs into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# getting URLs from each pages\n",
    "\n",
    "ottawa_df = pd.DataFrame()\n",
    "counter=0\n",
    "for file in os.listdir(project_folder+'saved_pages/hamilton/1200kp'):\n",
    "    html_file = project_folder+'saved_pages/hamilton/1200kp/{}'.format(file)\n",
    "    soup = BeautifulSoup(io.open(html_file, encoding=\"utf-8\"), \"html.parser\")\n",
    "    data = soup.find_all(class_=\"cardCon\")\n",
    "    print(file)\n",
    "    for i, elem in enumerate(data):\n",
    "        price = data[i].find(class_=\"listingCardPrice\").get_text()\n",
    "        address = data[i].find(class_=\"listingCardAddress\").get_text()\n",
    "        rooms = data[i].find_all(class_=\"listingCardIconNum\")\n",
    "        #print(data[i].find(class_=\"notificationCon listingDetailsLink\"))\n",
    "        #print(data[i].find(class_=\"notificationCon listingDetailsLink\"))\n",
    "        if data[i].find(class_=\"blockLink listingDetailsLink\")== None:\n",
    "            url=\"None\"\n",
    "            print(\"no url\")\n",
    "        else:\n",
    "            url = data[i].find(class_=\"blockLink listingDetailsLink\")['href']\n",
    "        \n",
    "        try:\n",
    "            bedrooms = rooms[0].get_text()\n",
    "        except:\n",
    "            print(\"unknown bedroom\")\n",
    "            bedrooms = \"Missing\"\n",
    "            \n",
    "        try:\n",
    "            bathrooms = rooms[1].get_text()\n",
    "        except:\n",
    "            print(\"unknown bathroom\")\n",
    "            bathrooms = \"Missing\"\n",
    "        try:\n",
    "            row_df = pd.DataFrame({'price': [price],\n",
    "                        'address': [address],\n",
    "                        'bedrooms': [bedrooms],\n",
    "                        'bathrooms': [bathrooms],\n",
    "                        'url': [url],\n",
    "                        'page': [file]})\n",
    "            ottawa_df = pd.concat([ottawa_df, row_df])\n",
    "            del row_df\n",
    "        except:\n",
    "            print(\"Error in record_{}\".format(i))\n",
    "\n",
    "\n",
    "# cleaning dataframe \n",
    "def cleaning_address(x):\n",
    "    return (x.replace(\"\\n\", \"\").strip())\n",
    "\n",
    "ottawa_df['address'] = ottawa_df['address'].apply(cleaning_address)\n",
    "    \n",
    "\n",
    "# saving data file \n",
    "ottawa_df.to_csv(project_folder+'output/hamilton_1200kp.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate Ottawa search result CSV files together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_part1=pd.read_csv(project_folder+\"output/ottawa_600k.csv\")\n",
    "df_part2=pd.read_csv(project_folder+\"output/ottawa_600k-1800k.csv\")\n",
    "df_part3=pd.read_csv(project_folder+\"output/ottawa_1800kp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_ottawa=pd.concat([df_part1, df_part2, df_part3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the search result CSV file that was just written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ottawa=pd.read_csv(project_folder+\"output/hamilton_1200kp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the list of URLs of the house listings from the search result CSV data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ottawa.head()\n",
    "list_links=list(df_ottawa[\"url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## number of listings in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(list_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(list_links[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visit the URLs and save the detailed house listing web pages to project_folder+\"saved_pages/\"+city+\"/\"+price_range+\"_details\"\n",
    "#### Example: \"saved_pages/hamilton/1200kp_details\" contains all pages for Hamilton house listings whose price is higher than 1200k\n",
    "### Ringtone \"alart.mp3\" will play if reCAPTCHA is triggered to tell the user to pass the human verification\n",
    "### User has 1 minute to pass the reCAPTCHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "import random\n",
    "driver = webdriver.Firefox(executable_path='C:/Users/hanson/OneDrive/Grad/Grad Project/bin/geckodriver')\n",
    "\n",
    "def scrapping_function_details(list_links, startstr):\n",
    "    i=1\n",
    "    for current_url in list_links:\n",
    "        link=str(startstr+current_url)\n",
    "        print(link)\n",
    "        driver.get(link)\n",
    "        time.sleep(random.uniform(2, 3))\n",
    "        elements = driver.find_elements_by_class_name(\"leftTableCell\")\n",
    "        print(elements)\n",
    "        # If \"leftTableCell\" does not exist,\n",
    "        # anti-scraping is triggered, give time to do human verification\n",
    "        if elements == []:\n",
    "            playsound('alart.mp3')\n",
    "            time.sleep(60) # 1 minute to do the \"I'm not robot\" verification\n",
    "        elements = driver.find_elements_by_class_name(\"leftTableCell\")\n",
    "        print(elements)\n",
    "        page = driver.page_source\n",
    "        file_ = io.open(project_folder+'saved_pages/hamilton/1200kp_details/page_{}.html'.format(i), 'w', encoding=\"utf-8\")\n",
    "        file_.write(page)\n",
    "        file_.close()\n",
    "        time.sleep(random.uniform(2, 3))\n",
    "        print(i)     \n",
    "        i += 1\n",
    "\n",
    "\n",
    "# calling scrapping function\n",
    "startstr=\"https://www.realtor.ca\" # the string needed to complete the web address\n",
    "scrapping_function_details(list_links, startstr)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features from the saved house listing web pages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df1=pd.read_csv(\"C:/Users/hanson/OneDrive/Grad/Grad Project/data_realtorCA/output/ottawa_600k.csv\")  \n",
    "df2=pd.read_csv(\"C:/Users/hanson/OneDrive/Grad/Grad Project/data_realtorCA/output/ottawa_600k-1800k.csv\")  \n",
    "df3=pd.read_csv(\"C:/Users/hanson/OneDrive/Grad/Grad Project/data_realtorCA/output/ottawa_1800kp.csv\")  \n",
    "result = pd.concat([df1,df2,df3])  \n",
    "len(result)  \n",
    "result.to_csv(\"C:/Users/hanson/OneDrive/Grad/Grad Project/data_realtorCA/output/ottawa_11May.csv\", index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the data extraction for all house listing web pages in 5 cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_folder=project_folder+\"output\"\n",
    "\n",
    "cityname=[\"toronto\",\"missi\",\"ottawa\",\"hamilton\",\"brampton\"]\n",
    "\n",
    "for city in cityname[2:]:\n",
    "    page_folder=project_folder+\"saved_pages/\"+city\n",
    "    \n",
    "    for subdir in os.listdir(page_folder):\n",
    "        if \"details\" in subdir:\n",
    "            subdir_path=page_folder + \"/\"+subdir\n",
    "            print(subdir_path)\n",
    "            data_extraction(subdir_path,city, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data extraction function that extract features from the saved house listing web pages and convert them into structured data frame saved as CSV file\n",
    "### Missing value is filled in as \"NotListed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# getting data from each pages\n",
    "from re import sub\n",
    "from decimal import Decimal\n",
    "\n",
    "\n",
    "def data_extraction(folder_details,city, folder_output):\n",
    "    df_ottawa=pd.read_csv(project_folder+\"/output/\"+city+\"_\"+folder_details.split(\"/\")[-1][:-8]+\".csv\")\n",
    "    list_links=list(df_ottawa[\"url\"])\n",
    "    ottawa_df = pd.DataFrame()\n",
    "    counter=0\n",
    "    for file in os.listdir(folder_details):\n",
    "        html_file = folder_details+'/{}'.format(file)\n",
    "        soup = BeautifulSoup(io.open(html_file, encoding=\"utf-8\"), \"html.parser\")\n",
    "        index_ls=int(str(file)[5:][0:-5])-1\n",
    "        url=str(\"https://www.realtor.ca\"+list_links[index_ls])\n",
    "\n",
    "        try:\n",
    "            data = soup.find_all('div',id=\"listingPrice\")\n",
    "            raw_price=[row.text for row in data][0]\n",
    "            price = Decimal(sub(r'[^\\d.]', '', raw_price))\n",
    "        except:\n",
    "            price=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data = soup.find_all(id=\"listingAddress\")\n",
    "            raw_address=[row.text for row in data][0]\n",
    "            raw_address=raw_address.strip() \n",
    "        except:\n",
    "            raw_address=\"NotListed\"\n",
    "\n",
    "        seperate_index=raw_address.find(', Ontario')\n",
    "        if seperate_index==-1:\n",
    "            address=\"NotListed\"\n",
    "        else:\n",
    "            address=raw_address[:seperate_index]\n",
    "\n",
    "        postal=raw_address[-6:]\n",
    "        if postal==\"Listed\":\n",
    "            postal=\"NotListed\"\n",
    "        if postal==\"ilable\":\n",
    "            postal=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data = soup.find_all(id=\"MLNumberVal\")\n",
    "            MLS=[row.text for row in data][0]\n",
    "            MLS=MLS.strip()\n",
    "        except:\n",
    "            MLS=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data = soup.find_all(id=\"propertyDescriptionCon\")\n",
    "            description=[row.text for row in data][0].strip()\n",
    "        except:\n",
    "            description=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_PropertyType\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            propertyType=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            propertyType=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_BuildingType\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            buildingType=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            buildingType=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_Stories\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            storeys=[row.text for row in data2][0].strip()\n",
    "\n",
    "        except:\n",
    "            storeys=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_NeighborhoodName\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            neighborhoodName=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            neighborhoodName=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_CommunityName\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            communityName=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            communityName=\"NotListed\"     \n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_Title\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            title=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            title=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_LandSize\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            landSize=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            landSize=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_BuiltIn\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            builtIn=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            builtIn=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_AnnualPropertyTaxes\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            propertyTaxes=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            propertyTaxes=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_ParkingType\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            parkingType=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            parkingType=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_AboveGrade\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            bedroomAboveGrade=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            bedroomAboveGrade=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_BelowGrade\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            bedroomBelowGrade=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            bedroomBelowGrade=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_Total\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            bathroomTotal=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            bathroomTotal=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_Partial\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            bathroomPartial=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            bathroomPartial=\"NotListed\"\n",
    "\n",
    "        #INTERIOR FEATURES\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_AppliancesIncluded\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            appliancesIncluded=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            appliancesIncluded=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_Flooring\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            flooring=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            flooring=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_BasementType\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            basementType=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            basementType=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_FixturesIncluded\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            FixturesIncluded=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            FixturesIncluded=\"NotListed\"\n",
    "\n",
    "        #BUILDING FEATURES\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_Features\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            buildingFeatures=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            buildingFeatures=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_FoundationType\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            foundationType=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            foundationType=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_Style\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            style=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            style=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_ArchitectureStyle\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            architectureStyle=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            architectureStyle=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_Structures\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            structures=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            structures=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_FireProtection\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            fireProtection=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            fireProtection=\"NotListed\"\n",
    "\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_BuildingAmenities\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            buildingAmenities=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            buildingAmenities=\"NotListed\"\n",
    "\n",
    "\n",
    "        #HEATING AND COOLING\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_Cooling\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            cooling=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            cooling=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_Fireplace\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            fireplace=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            fireplace=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_HeatingType\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            heatingType=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            heatingType=\"NotListed\"\n",
    "\n",
    "        #Utilities\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_UtilitySewer\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            sewer=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            sewer=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_UtilityWater\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            water=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            water=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_UtilityCommunications\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            utilityCommunications=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            utilityCommunications=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_UtilityType\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            utilityType=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            utilityType=\"NotListed\"\n",
    "\n",
    "        #Exterior Finish\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_ExteriorFinish\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            exteriorFinish=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            exteriorFinish=\"NotListed\"\n",
    "\n",
    "        #Neighborhood Features\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_CommunityFeatures\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            communityFeatures=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            communityFeatures=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_AmenitiesNearby\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            amenitiesNearby=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            amenitiesNearby=\"NotListed\"\n",
    "\n",
    "        #PARKING\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_ParkingType\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            parkingType=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            parkingType=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_TotalParkingSpaces\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            totalParkingSpaces=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            totalParkingSpaces=\"NotListed\"\n",
    "\n",
    "        #Condo information\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_MonthlyMaintenanceFees\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            maintenanceFees=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            maintenanceFees=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_MaintenanceFeesInclude\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            maintenanceFeesInclude=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            maintenanceFeesInclude=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionVal_MaintenanceManagementCompany\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            maintenanceManagementCompany=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            maintenanceManagementCompany=\"NotListed\"\n",
    "\n",
    "\n",
    "        #ROOMS skipped\n",
    "\n",
    "        #Land\n",
    "        ##lot features\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_Fencing\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            fencing=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            fencing=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_Frontage\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            frontage=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            frontage=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_LandDepth\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            landDepth=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            landDepth=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_RoadType\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            roadType=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            roadType=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_RoadView\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            view=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            view=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_PresentUse\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            presentUse=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            presentUse=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_LandscapeFeatures\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            landscapeFeatures=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            landscapeFeatures=\"NotListed\"\n",
    "\n",
    "        ##Other property information\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_Access\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            access=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            access=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_ZoningDescription\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            zoningDescription=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            zoningDescription=\"NotListed\"\n",
    "\n",
    "        ##waterfront features\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_SurfaceWater\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            surfaceWater=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            surfaceWater=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_Features\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            waterfrontFeatures=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            waterfrontFeatures=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            data2 = soup.find(\"div\", {\"id\": \"propertyDetailsSectionContentSubCon_Waterfront\"}).find_all(class_=\"propertyDetailsSectionContentValue\")\n",
    "            waterfront=[row.text for row in data2][0].strip()\n",
    "        except:\n",
    "            waterfront=\"NotListed\"\n",
    "\n",
    "        try:\n",
    "            row_df = pd.DataFrame({'url': [url],\n",
    "                        'price': [price],\n",
    "                        'address': [address],\n",
    "                        'postal': [postal],\n",
    "                        'MLS': [MLS],\n",
    "                        'description': [description],\n",
    "                        'propertyType':[propertyType],\n",
    "                        'buildingType':[buildingType],\n",
    "                        'storeys':[storeys],\n",
    "                        'neighborhoodName':[neighborhoodName],\n",
    "                        'communityName':[communityName],\n",
    "                        'title':[title],\n",
    "                        'landSize':[landSize],\n",
    "                        'builtIn':[builtIn],\n",
    "                        'propertyTaxes':[propertyTaxes],\n",
    "                        'parkingType':[parkingType],\n",
    "                        'bedroomAboveGrade':[bedroomAboveGrade],\n",
    "                        'bedroomBelowGrade':[bedroomBelowGrade],\n",
    "                        'bathroomTotal':[bathroomTotal],\n",
    "                        'bathroomPartial':[bathroomPartial],\n",
    "                        'appliancesIncluded':[appliancesIncluded],\n",
    "                        'flooring':[flooring],\n",
    "                        'basementType':[basementType],\n",
    "                        'FixturesIncluded':[FixturesIncluded],\n",
    "                        'buildingFeatures':[buildingFeatures],\n",
    "                        'foundationType':[foundationType],\n",
    "                        'style':[style],\n",
    "                        'architectureStyle':[architectureStyle],\n",
    "                        'structures':[structures],\n",
    "                        'fireProtection':[fireProtection],\n",
    "                        'buildingAmenities':[buildingAmenities],\n",
    "                        'cooling':[cooling],\n",
    "                        'fireplace':[fireplace],\n",
    "                        'heatingType':[heatingType],\n",
    "                        'sewer':[sewer],\n",
    "                        'water':[water],\n",
    "                        'utilityCommunications':[utilityCommunications],\n",
    "                        'utilityType':[utilityType],\n",
    "                        'exteriorFinish':[exteriorFinish],\n",
    "                        'communityFeatures':[communityFeatures],\n",
    "                        'amenitiesNearby':[amenitiesNearby],\n",
    "                        'parkingType':[parkingType],\n",
    "                        'totalParkingSpaces':[totalParkingSpaces],\n",
    "                        'maintenanceFees':[maintenanceFees],\n",
    "                        'maintenanceFeesInclude':[maintenanceFeesInclude],\n",
    "                        'maintenanceManagementCompany':[maintenanceManagementCompany],\n",
    "                        'fencing':[fencing],\n",
    "                        'frontage':[frontage],\n",
    "                        'landDepth':[landDepth],\n",
    "                        'roadType':[roadType],\n",
    "                        'view':[view],\n",
    "                        'presentUse':[presentUse],\n",
    "                        'landscapeFeatures':[landscapeFeatures],\n",
    "                        'access':[access],\n",
    "                        'zoningDescription':[zoningDescription],\n",
    "                        'surfaceWater':[surfaceWater],\n",
    "                        'waterfrontFeatures':[waterfrontFeatures],\n",
    "                        'waterfront':[waterfront]})\n",
    "            ottawa_df = pd.concat([ottawa_df, row_df])\n",
    "            del row_df\n",
    "        except:\n",
    "            print(\"Error in record:\"+str(file))\n",
    "        counter=counter+1\n",
    "\n",
    "    ottawa_df.to_csv(folder_output+\"/\"+city+\"_\"+folder_details.split(\"/\")[-1]+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the result data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ottawa_df=ottawa_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ottawa_df[ottawa_df[\"address\"]==\"NotListed\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The end of the crawler that works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following shows the failed attempt to develop a crawler for \"REALTOR.ca\" using Python requests package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretend to be browser using fake_useragent package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "import requests\n",
    "\n",
    "\n",
    "#ua = UserAgent()\n",
    "#print(ua.chrome)\n",
    "#header = {'User-Agent':str(ua.chrome), 'Accept-Encoding': 'identity'}\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try to scrape data from \"REALTOR.ca\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ottawa, price from 0 to 550,000 inclusive\n",
    "#link= \"https://www.ottawarealestate.ca/search/details/oo/0/\"\n",
    "link = \"https://www.realtor.ca/map#ZoomLevel=10&Center=45.250322%2C-75.799950&LatitudeMax=45.63429&LongitudeMax=-74.71230&LatitudeMin=44.86374&LongitudeMin=-76.88760&view=list&Sort=1-A&GeoIds=g30_f241etq5&GeoName=Ottawa%2C%20ON&PropertyTypeGroupID=1&PropertySearchTypeId=1&TransactionTypeId=2&PriceMax=550000&Currency=CAD\"\n",
    "response = get(link, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The response code is 200, it means success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### However, the content shows that the website detected the crawler and did not give us the data we needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try another website, OttawaRealEstate.ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link= \"https://www.ottawarealestate.ca/search/details/oo/0/\"\n",
    "response = get(link, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The response code is 200, it means success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The content is correct, this could be used to scrape the local real estate website \"OttawaRealEstate.ca\"\n",
    "### It also means that the \"REALTOR.ca\" website has a more strict anti-scraping mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
